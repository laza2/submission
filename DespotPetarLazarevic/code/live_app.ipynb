{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4ee24d0b-90ca-4b66-a321-412c28df4fe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the required libraries.\n",
    "import os\n",
    "import cv2\n",
    "import math\n",
    "import random\n",
    "import numpy as np\n",
    "import datetime as dt\n",
    "import tensorflow as tf\n",
    "from collections import deque\n",
    "import matplotlib.pyplot as plt\n",
    "from threading import Thread\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.utils import plot_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "12327803-6785-4faf-b0f3-8b5cd732c891",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the height and width to which each video frame will be resized in our dataset.\n",
    "IMAGE_HEIGHT , IMAGE_WIDTH = 64, 64\n",
    "\n",
    "# Specify the number of frames of a video that will be fed to the model as one sequence.\n",
    "SEQUENCE_LENGTH = 10\n",
    "\n",
    "# Specify the directory containing the UCF50 dataset. \n",
    "DATASET_DIR = \"dataset\"\n",
    "\n",
    "# Specify the list containing the names of the classes used for training. Feel free to choose any set of classes.\n",
    "CLASSES_LIST = [\"0\", \"1\", \"2\", \"3\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "acfd4e7d-3eb9-45cb-89f4-1c2cb8cb8f41",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_LRCN_model():\n",
    "    '''\n",
    "    This function will construct the required LRCN model.\n",
    "    Returns:\n",
    "        model: It is the required constructed LRCN model.\n",
    "    '''\n",
    "\n",
    "    # We will use a Sequential model for model construction.\n",
    "    model = Sequential()\n",
    "    \n",
    "    # Define the Model Architecture.\n",
    "    ########################################################################################################################\n",
    "    \n",
    "    model.add(TimeDistributed(Conv2D(16, (3, 3), padding='same',activation = 'relu'),\n",
    "                              input_shape = (SEQUENCE_LENGTH, IMAGE_HEIGHT, IMAGE_WIDTH, 3)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(TimeDistributed(MaxPooling2D((4, 4)))) \n",
    "    model.add(TimeDistributed(Dropout(0.25)))\n",
    "    \n",
    "    model.add(TimeDistributed(Conv2D(32, (3, 3), padding='same',activation = 'relu')))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(TimeDistributed(MaxPooling2D((4, 4))))\n",
    "    model.add(TimeDistributed(Dropout(0.25)))\n",
    "    \n",
    "    model.add(TimeDistributed(Conv2D(64, (3, 3), padding='same',activation = 'relu')))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(TimeDistributed(MaxPooling2D((2, 2))))\n",
    "    model.add(TimeDistributed(Dropout(0.25)))\n",
    "    \n",
    "    model.add(TimeDistributed(Conv2D(64, (3, 3), padding='same',activation = 'relu')))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(TimeDistributed(MaxPooling2D((2, 2))))\n",
    "    model.add(TimeDistributed(Dropout(0.25)))\n",
    "                                      \n",
    "    model.add(TimeDistributed(Flatten()))\n",
    "                                      \n",
    "    model.add(LSTM(32))\n",
    "    \n",
    "    model.add(Dense(len(CLASSES_LIST), activation = 'softmax'))\n",
    "    \n",
    "    ########################################################################################################################\n",
    "\n",
    "    # Display the models summary.\n",
    "    model.summary()\n",
    "    \n",
    "    # Return the constructed LRCN model.\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4ed2d96c-321a-49be-811b-55764abff6fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "time_distributed (TimeDistri (None, 10, 64, 64, 16)    448       \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 10, 64, 64, 16)    64        \n",
      "_________________________________________________________________\n",
      "time_distributed_1 (TimeDist (None, 10, 16, 16, 16)    0         \n",
      "_________________________________________________________________\n",
      "time_distributed_2 (TimeDist (None, 10, 16, 16, 16)    0         \n",
      "_________________________________________________________________\n",
      "time_distributed_3 (TimeDist (None, 10, 16, 16, 32)    4640      \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 10, 16, 16, 32)    128       \n",
      "_________________________________________________________________\n",
      "time_distributed_4 (TimeDist (None, 10, 4, 4, 32)      0         \n",
      "_________________________________________________________________\n",
      "time_distributed_5 (TimeDist (None, 10, 4, 4, 32)      0         \n",
      "_________________________________________________________________\n",
      "time_distributed_6 (TimeDist (None, 10, 4, 4, 64)      18496     \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 10, 4, 4, 64)      256       \n",
      "_________________________________________________________________\n",
      "time_distributed_7 (TimeDist (None, 10, 2, 2, 64)      0         \n",
      "_________________________________________________________________\n",
      "time_distributed_8 (TimeDist (None, 10, 2, 2, 64)      0         \n",
      "_________________________________________________________________\n",
      "time_distributed_9 (TimeDist (None, 10, 2, 2, 64)      36928     \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 10, 2, 2, 64)      256       \n",
      "_________________________________________________________________\n",
      "time_distributed_10 (TimeDis (None, 10, 1, 1, 64)      0         \n",
      "_________________________________________________________________\n",
      "time_distributed_11 (TimeDis (None, 10, 1, 1, 64)      0         \n",
      "_________________________________________________________________\n",
      "time_distributed_12 (TimeDis (None, 10, 64)            0         \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  (None, 32)                12416     \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 4)                 132       \n",
      "=================================================================\n",
      "Total params: 73,764\n",
      "Trainable params: 73,412\n",
      "Non-trainable params: 352\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "lrcn_model = create_LRCN_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71d90e65",
   "metadata": {},
   "source": [
    "Choose one of the pre-trained weights.\n",
    "Difference is in datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6d192b56-bb08-4c78-a345-6ad6a11436f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sanity check: [[6.9648826e-01 2.9688773e-01 4.1595515e-04 6.2080184e-03]] %\n"
     ]
    }
   ],
   "source": [
    "#weights_lrcn = \"5LRCN_model___Date_Time_2022_05_26__11_11_27___Loss_0.648440957069397___Accuracy_0.7206477522850037.h5\"\n",
    "#weights_lrcn = \"6LRCN_model_second_dataset_3deadrows_seq5.h5\"\n",
    "weights_lrcn = \"6LRCN_model__double_data_seq5_3deadrows.h5\"\n",
    "#weights_lrcn = '7LRCN_model___Date_Time_2022_05_26__17_00_07___Loss_0.6486591696739197___Accuracy_0.7248986959457397.h5'\n",
    "lrcn_model.load_weights(weights_lrcn)\n",
    "print(f'Sanity check: {lrcn_model.predict(np.random.random((1,10,64,64,3)))} %')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "79811470-776e-4ffe-8425-af1d6bad2fdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ifxdaq\n",
    "import processing\n",
    "import numpy as np\n",
    "#print(ifxdaq.__version__)\n",
    "from ifxdaq.sensor.radar_ifx import RadarIfxAvian\n",
    "import os\n",
    "\n",
    "config_file = \"radar_configs/RadarIfxBGT60.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bbbd70a8-8727-4615-8ba4-47ad2985ddee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With the current configuration, the radar will send out 64 signals with varying frequency (\"chirps\") between 60.5 GHz and 61.5 GHz.\n",
      "Each chirp will consist of 128 ADC measurements of the IF signal (\"samples\").\n",
      "A chirp takes 64.0 microseconds and the delay between the chirps is 400.0 microseconds.\n",
      "With a total frame duration of 29.696 milliseconds and a delay of 50.0 milliseconds between the frame we get a frame rate of 12.547681188516362 radar frames per second.\n"
     ]
    }
   ],
   "source": [
    "## Run this to understand the current radar settings better\n",
    "import json\n",
    "with open(config_file) as json_file:\n",
    "    c = json.load(json_file)[\"device_config\"][\"fmcw_single_shape\"]\n",
    "    chirp_duration = c[\"num_samples_per_chirp\"]/c['sample_rate_Hz']\n",
    "    frame_duration = (chirp_duration + c['chirp_repetition_time_s']) * c['num_chirps_per_frame']\n",
    "    print(\"With the current configuration, the radar will send out \" + str(c['num_chirps_per_frame']) + \\\n",
    "          ' signals with varying frequency (\"chirps\") between ' + str(c['start_frequency_Hz']/1e9) + \" GHz and \" + \\\n",
    "          str(c['end_frequency_Hz']/1e9) + \" GHz.\")\n",
    "    print('Each chirp will consist of ' + str(c[\"num_samples_per_chirp\"]) + ' ADC measurements of the IF signal (\"samples\").')\n",
    "    print('A chirp takes ' + str(chirp_duration*1e6) + ' microseconds and the delay between the chirps is ' + str(c['chirp_repetition_time_s']*1e6) +' microseconds.')\n",
    "    print('With a total frame duration of ' + str(frame_duration*1e3) + ' milliseconds and a delay of ' + str(c['frame_repetition_time_s']*1e3) + ' milliseconds between the frame we get a frame rate of ' + str(1/(frame_duration + c['frame_repetition_time_s'])) + ' radar frames per second.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1d3fd7e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def CNN_LSTM(range_doppler_map):\n",
    "        range_doppler_map[:,:,:,0] /= np.max(range_doppler_map[:,:,:,0])\n",
    "        range_doppler_map[:,:,:,1] /= np.max(range_doppler_map[:,:,:,1])\n",
    "        range_doppler_map[:,:,:,2] /= np.max(range_doppler_map[:,:,:,2])\n",
    "        pred = lrcn_model.predict(range_doppler_map[None,...])\n",
    "        print(np.argmax(pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6443968f-e46a-4f11-a841-70329607e98c",
   "metadata": {},
   "source": [
    "### LRCN with aggregated data processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5885ebe3-e6d8-43ad-9d3c-7d00ce6fd5cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "data_buffer = np.zeros((1,5,3,64,128))\n",
    "counter = 0\n",
    "sequence_size = 5\n",
    "\n",
    "number_of_frames=500\n",
    "\n",
    "t1 = time.time()\n",
    "with RadarIfxAvian(config_file) as device:                             # Initialize the radar with configurations\n",
    "    \n",
    "    for i_frame, frame in enumerate(device):                           # Loop through the frames coming from the radar\n",
    "        \n",
    "        raw_data_frame = np.squeeze(frame['radar'].data/(4095.0))      # Dividing by 4095.0 to scale the data\n",
    "        \n",
    "        data_buffer[0,counter,...] = raw_data_frame\n",
    "        counter = (counter + 1) % sequence_size\n",
    "        \n",
    "        if i_frame < sequence_size: continue\n",
    "        \n",
    "        input_data = np.concatenate((data_buffer[0,counter:,...], data_buffer[0,:counter,...]))\n",
    "        range_doppler_map = np.abs(processing.processing_rangeDopplerData(input_data).transpose((0,2,3,1)))\n",
    "        range_doppler_map[:,31:34,:,:] = 0\n",
    "        t = Thread(target=CNN_LSTM, args=(range_doppler_map/255,))\n",
    "        t.start()\n",
    "        t.join()\n",
    "        \n",
    "        if(i_frame == number_of_frames-1):\n",
    "            break   \n",
    "            \n",
    "t2 = time.time()\n",
    "\n",
    "print(f\"Elapsed time: {t2-t1:.2f}s\")\n",
    "print(f\"Frame rate: {number_of_frames/(t2-t1)}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
